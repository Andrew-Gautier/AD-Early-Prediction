{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly get all variables we are considering appended to a raw dataframe. \n",
    "Work on the 2visit first as its the largest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ID, Visit, Prog_ID, Progression]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "non_prog = pd.read_csv('Cohorts\\\\NonProgressors\\\\cleaned_20visit_nonprogressor.csv')\n",
    "prog = pd.read_csv('Cohorts\\\\Progressors\\\\cleaned_20visit_progressors.csv')\n",
    "\n",
    "# Read the CSV files and extract IDs\n",
    "non_prog_ids = non_prog['NACCID'].tolist()\n",
    "prog_ids = prog['NACCID'].tolist()\n",
    "progvecs = prog.iloc[:, 1:].values\n",
    "nonprogvecs = non_prog.iloc[:, 1:].values\n",
    "\n",
    "# Create a new dataframe with IDs and labels\n",
    "ids = non_prog_ids + prog_ids\n",
    "labels = [0] * len(non_prog_ids) + [1] * len(prog_ids)\n",
    "vectors = np.concatenate((nonprogvecs, progvecs), axis=0)\n",
    "\n",
    "data = []\n",
    "for id, label, vector in zip(ids, labels, vectors):\n",
    "    for visit, value in enumerate(vector, start=1):\n",
    "        data.append((id, visit, label, value))\n",
    "\n",
    "df_combined = pd.DataFrame(data, columns=['ID', 'Visit', 'Prog_ID', 'Progression'])\n",
    "\n",
    "# Set MultiIndex\n",
    "#df_combined.set_index(['ID', 'Visit'], inplace=True)\n",
    "\n",
    "# Print the DataFrame to verify\n",
    "print(df_combined)\n",
    "\n",
    "df_combined.to_csv('Cohorts\\\\20visit_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-29-25\n",
    "I am doing a check on some of these comborbidities to see if they just have one entry or have multiple, there is an issue with the add columns function converting everything to NaN so I'm going back and checking the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\AppData\\Local\\Temp\\ipykernel_18080\\197921392.py:10: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uds_df = pd.read_csv('uds.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame for 5visit_combined.csv:\n",
      "   Unnamed: 0          ID  Prog_ID      Progression  SEX  EDUC  ALCOHOL  \\\n",
      "0           0  NACC004056        0  (0, 0, 0, 0, 0)    2    19        0   \n",
      "1           1  NACC038334        0  (0, 0, 0, 0, 0)    2    18        0   \n",
      "2           2  NACC061339        0  (0, 0, 0, 0, 0)    2    16        0   \n",
      "3           3  NACC158860        0  (0, 0, 0, 0, 0)    2    99        0   \n",
      "4           4  NACC222069        0  (0, 0, 0, 0, 0)    2    18        0   \n",
      "\n",
      "                                  BMI                  MMSE              GDS  \\\n",
      "0     [888.8, 33.5, 33.2, 33.2, 32.8]  [97, 97, 97, 97, 30]  [1, 0, 0, 0, 2]   \n",
      "1     [22.8, 888.8, 22.5, 22.3, 22.8]  [30, 29, 30, 30, 30]  [2, 1, 1, 5, 4]   \n",
      "2      [21.4, 21.9, 20.8, 20.6, 21.5]  [30, 30, -4, -4, -4]  [1, 0, 0, 1, 1]   \n",
      "3  [888.8, 27.2, 888.8, 888.8, 888.8]  [-4, -4, -4, -4, -4]  [1, 1, 1, 2, 1]   \n",
      "4  [888.8, 888.8, 26.5, 888.8, 888.8]  [29, -4, -4, -4, -4]  [0, 0, 0, 1, 0]   \n",
      "\n",
      "   ... DIABETES HYPERCHO HYPERTEN B12DEF DEPD ANX NACCTBI SMOKYRS RACE ANYMEDS  \n",
      "0  ...        0        0        1      0    0   0       0       0    5       1  \n",
      "1  ...        0        1        0      0    0   0       0       0    1       1  \n",
      "2  ...        0        0        0      0    0   0       0       0    1       1  \n",
      "3  ...        0        1        0      0    0   0       0       0    1       1  \n",
      "4  ...        0        0        0      0    0   0       0       0    1       1  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\AppData\\Local\\Temp\\ipykernel_18080\\197921392.py:10: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uds_df = pd.read_csv('uds.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame for 6visit_combined.csv:\n",
      "   Unnamed: 0          ID  Prog_ID         Progression  SEX  EDUC  ALCOHOL  \\\n",
      "0           0  NACC090138        0  (0, 0, 0, 0, 0, 0)    2    12        0   \n",
      "1           1  NACC096993        0  (0, 0, 0, 0, 0, 0)    2    16        0   \n",
      "2           2  NACC109706        0  (0, 0, 0, 0, 0, 0)    1    12        0   \n",
      "3           3  NACC121993        0  (0, 0, 0, 0, 0, 0)    1    16        0   \n",
      "4           4  NACC205803        0  (0, 0, 0, 0, 0, 0)    2    13        0   \n",
      "\n",
      "                                      BMI                      MMSE  \\\n",
      "0  [24.9, 23.6, 23.2, 888.8, -4.0, 888.8]  [30, 29, -4, -4, -4, -4]   \n",
      "1   [888.8, 22.9, 21.2, 21.2, 21.2, 24.3]  [30, 30, 29, 29, 29, 29]   \n",
      "2   [888.8, 29.0, 27.1, 24.1, 24.7, 26.4]  [30, 28, 30, 30, 30, 30]   \n",
      "3   [888.8, 20.8, 20.6, 21.6, 21.1, 18.9]  [97, 97, 97, 97, 97, 97]   \n",
      "4    [19.1, 19.1, 18.7, 18.5, 18.3, -4.0]  [97, 97, 28, -4, -4, -4]   \n",
      "\n",
      "                   GDS  ... DIABETES HYPERCHO HYPERTEN B12DEF DEPD ANX  \\\n",
      "0  [0, 0, 0, 0, -4, 0]  ...        0        1        1      0    0   0   \n",
      "1   [0, 0, 0, 0, 0, 0]  ...        0        1        0      0    0   0   \n",
      "2   [0, 0, 1, 0, 0, 1]  ...        0        1        0      0    0   0   \n",
      "3   [0, 0, 0, 0, 0, 2]  ...        0        0        0      0    0   0   \n",
      "4   [0, 0, 0, 1, 2, 2]  ...        2        2        9      9    0   0   \n",
      "\n",
      "  NACCTBI SMOKYRS RACE ANYMEDS  \n",
      "0       1      10   99       1  \n",
      "1       0       0    1       1  \n",
      "2       0      30    1       1  \n",
      "3       0       0    5       1  \n",
      "4       0       0    5       0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\AppData\\Local\\Temp\\ipykernel_18080\\197921392.py:10: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uds_df = pd.read_csv('uds.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame for 7visit_combined.csv:\n",
      "   Unnamed: 0          ID  Prog_ID            Progression  SEX  EDUC  ALCOHOL  \\\n",
      "0           0  NACC037512        0  (0, 0, 0, 0, 0, 0, 0)    1    18        0   \n",
      "1           1  NACC073844        0  (0, 0, 0, 0, 0, 0, 0)    1    18        0   \n",
      "2           2  NACC122992        0  (0, 0, 0, 0, 0, 0, 0)    1    12        0   \n",
      "3           3  NACC159991        0  (0, 0, 0, 0, 0, 0, 0)    1    18        0   \n",
      "4           4  NACC164852        0  (0, 0, 0, 0, 0, 0, 0)    1    18        0   \n",
      "\n",
      "                                           BMI                          MMSE  \\\n",
      "0   [21.5, 20.7, 21.0, 20.9, 21.0, -4.0, 21.4]  [30, 30, 30, 30, 30, -4, 30]   \n",
      "1  [888.8, 23.7, 24.0, 24.5, 25.0, -4.0, 24.4]  [30, 30, 30, 30, 29, -4, -4]   \n",
      "2   [32.8, 34.4, 33.3, 32.9, -4.0, 31.3, 29.5]  [29, 27, -4, -4, -4, -4, -4]   \n",
      "3   [22.6, 22.1, 22.6, 26.3, 23.3, -4.0, 22.9]  [30, 30, 30, 29, 30, -4, -4]   \n",
      "4   [29.6, 29.6, 31.0, 29.5, -4.0, 29.0, 28.3]  [-4, -4, -4, -4, -4, -4, -4]   \n",
      "\n",
      "                       GDS  ... DIABETES HYPERCHO HYPERTEN B12DEF DEPD ANX  \\\n",
      "0   [0, 1, 0, 0, 0, -4, 0]  ...        0        0        1      0    0   0   \n",
      "1   [0, 1, 2, 1, 0, -4, 0]  ...        0        0        0      0    0   0   \n",
      "2  [3, 0, 0, -4, -4, 0, 0]  ...        0        1        0      0    0   0   \n",
      "3   [0, 0, 0, 0, 0, -4, 0]  ...        0        0        1      0    0   0   \n",
      "4    [0, 3, 0, 0, 0, 0, 0]  ...        1        0        0      0    0   0   \n",
      "\n",
      "  NACCTBI SMOKYRS RACE ANYMEDS  \n",
      "0       1      30    1       1  \n",
      "1       0       0    1       1  \n",
      "2       1      16   99       1  \n",
      "3       0       0    1       1  \n",
      "4       0       0    5       1  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\AppData\\Local\\Temp\\ipykernel_18080\\197921392.py:10: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uds_df = pd.read_csv('uds.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame for 8visit_combined.csv:\n",
      "   Unnamed: 0          ID  Prog_ID               Progression  SEX  EDUC  \\\n",
      "0           0  NACC134016        0  (0, 0, 0, 0, 0, 0, 0, 0)    2    18   \n",
      "1           1  NACC205485        0  (0, 0, 0, 0, 0, 0, 0, 0)    1    16   \n",
      "2           2  NACC256391        0  (0, 0, 0, 0, 0, 0, 0, 0)    2    20   \n",
      "3           3  NACC296437        0  (0, 0, 0, 0, 0, 0, 0, 0)    2    18   \n",
      "4           4  NACC525841        0  (0, 0, 0, 0, 0, 0, 0, 0)    1    12   \n",
      "\n",
      "   ALCOHOL                                                BMI  \\\n",
      "0        0  [888.8, 22.8, 888.8, 26.2, 888.8, 26.9, 28.3, ...   \n",
      "1        0  [27.1, 888.8, -4.0, 28.9, 888.8, 26.7, 888.8, ...   \n",
      "2        0  [20.2, 21.5, 21.6, 21.8, 23.4, 21.8, 888.8, 24.5]   \n",
      "3        0  [888.8, 30.2, 29.6, 33.0, 32.0, 33.0, -4.0, 28.5]   \n",
      "4        0   [23.5, 22.3, 23.2, 23.3, -4.0, 22.6, 22.1, 21.9]   \n",
      "\n",
      "                               MMSE                          GDS  ...  \\\n",
      "0  [30, 29, 28, 28, 30, 30, 27, -4]    [0, 0, 0, 0, 0, 0, 0, -4]  ...   \n",
      "1  [30, 29, -4, -4, -4, -4, -4, -4]  [7, 7, -4, 7, 10, 9, 6, -4]  ...   \n",
      "2  [30, 30, 29, -4, -4, -4, -4, -4]     [0, 0, 1, 0, 0, 1, 1, 0]  ...   \n",
      "3  [28, 29, 30, 28, 29, 28, -4, 30]    [0, 0, 0, 0, 0, 0, -4, 0]  ...   \n",
      "4  [29, 29, 29, 30, -4, -4, -4, -4]    [1, 1, 2, 1, -4, 0, 0, 1]  ...   \n",
      "\n",
      "  DIABETES HYPERCHO HYPERTEN B12DEF DEPD ANX NACCTBI SMOKYRS RACE ANYMEDS  \n",
      "0        0        0        0      0    0   0       0      30    1       1  \n",
      "1        1        0        0      0    1   0       0       0    1       1  \n",
      "2        0        0        0      0    0   0       0       0    1       1  \n",
      "3        0        1        1      0    0   0       1       1    1       1  \n",
      "4        0        2        0      0    0   0       0       0    1       1  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\AppData\\Local\\Temp\\ipykernel_18080\\197921392.py:10: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  uds_df = pd.read_csv('uds.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame for 9visit_combined.csv:\n",
      "   Unnamed: 0          ID  Prog_ID                  Progression  SEX  EDUC  \\\n",
      "0           0  NACC062239        0  (0, 0, 0, 0, 0, 0, 0, 0, 0)    2    18   \n",
      "1           1  NACC072185        0  (0, 0, 0, 0, 0, 0, 0, 0, 0)    2    18   \n",
      "2           2  NACC077465        0  (0, 0, 0, 0, 0, 0, 0, 0, 0)    2    16   \n",
      "3           3  NACC198211        0  (0, 0, 0, 0, 0, 0, 0, 0, 0)    2    18   \n",
      "4           4  NACC217214        0  (0, 0, 0, 0, 0, 0, 0, 0, 0)    1    20   \n",
      "\n",
      "   ALCOHOL                                                BMI  \\\n",
      "0        0  [23.7, 25.4, 24.8, 25.2, -4.0, 25.3, 26.0, 25....   \n",
      "1        0  [19.8, 20.1, 21.3, 20.4, 20.1, -4.0, 19.9, 19....   \n",
      "2        0  [22.9, 26.7, 21.6, 22.9, 888.8, -4.0, 888.8, 2...   \n",
      "3        0  [20.5, 20.6, 20.6, 20.0, -4.0, -4.0, 19.3, 19....   \n",
      "4        0  [24.1, 888.8, -4.0, 24.7, 23.9, 22.0, -4.0, 23...   \n",
      "\n",
      "                                   MMSE                            GDS  ...  \\\n",
      "0  [30, 30, 30, 30, -4, -4, -4, -4, -4]   [0, 0, 0, 0, -4, 0, 0, 0, 0]  ...   \n",
      "1  [30, 30, 29, 30, 30, -4, -4, -4, -4]   [0, 0, 0, 0, 0, -4, 0, 0, 0]  ...   \n",
      "2  [30, 30, 30, 30, 29, -4, -4, -4, -4]   [3, 3, 2, 2, 0, -4, 2, 2, 3]  ...   \n",
      "3  [30, 29, 30, 30, -4, -4, -4, -4, -4]  [0, 0, 0, 0, -4, -4, 0, 1, 2]  ...   \n",
      "4  [30, 29, -4, -4, -4, -4, -4, -4, -4]   [1, 1, -4, 1, 1, 0, 1, 1, 0]  ...   \n",
      "\n",
      "  DIABETES HYPERCHO HYPERTEN B12DEF DEPD ANX NACCTBI SMOKYRS RACE ANYMEDS  \n",
      "0        0        1        0      0    0   0       0       0    1       1  \n",
      "1        0        2        0      0    0   0       1       0    1       1  \n",
      "2        0        1        0      0    0   1       0      20    1       1  \n",
      "3        0        0        0      0    0   1       0      10    1       1  \n",
      "4        0        1        0      0    0   0       0      16    1       1  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store the vectors for each ID\n",
    "cohorts_dir = 'Cohorts'\n",
    "for root, dirs, files in os.walk(cohorts_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            test_df = pd.read_csv(file_path)\n",
    "            if 'ANYMEDS' in test_df.columns:\n",
    "                continue\n",
    "            uds_df = pd.read_csv('uds.csv')\n",
    "            \n",
    "            # Create dictionaries to store the vectors for each ID\n",
    "            # naccfam_vectors = {}\n",
    "            # cvhatt_vectors = {}\n",
    "            # cvafib_vectors = {}\n",
    "            # diabetes_vectors = {}\n",
    "            # hypercho_vectors = {}\n",
    "            # hyperten_vectors = {}\n",
    "            # b12def_vectors = {}\n",
    "            # depd_vectors = {}\n",
    "            # anx_vectors = {}\n",
    "            # nacctbi_vectors = {}\n",
    "            anymeds_vectors = {}\n",
    "            # Iterate through each unique ID in the test_df\n",
    "            for id in test_df['ID'].unique():\n",
    "                # Get the values for the current ID, ignoring -4 entries\n",
    "                # naccfam_values = [v for v in uds_df.loc[uds_df['NACCID'] == id, 'NACCFAM'].tolist() if v != -4]\n",
    "                # cvhatt_values = [v for v in uds_df.loc[uds_df['NACCID'] == id, 'CVHATT'].tolist() if v != -4]\n",
    "                # cvafib_values = [v for v in uds_df.loc[uds_df['NACCID'] == id, 'CVAFIB'].tolist() if v != -4]\n",
    "                # diabetes_values = [v for v in uds_df.loc[uds_df['NACCID'] == id, 'DIABETES'].tolist() if v != -4]\n",
    "                # hypercho_values = [v for v in uds_df.loc[uds_df['NACCID'] == id, 'HYPERCHO'].tolist() if v != -4]\n",
    "                # hyperten_values = [v for v in uds_df.loc[uds_df['NACCID'] == id, 'HYPERTEN'].tolist() if v != -4]\n",
    "                # b12def_values = [v for v in uds_df.loc[uds_df['NACCID'] == id, 'B12DEF'].tolist() if v != -4]\n",
    "                # depd_values = [v for v in uds_df.loc[uds_df['NACCID'] == id, 'DEPD'].tolist() if v != -4]\n",
    "                # anx_values = [v for v in uds_df.loc[uds_df['NACCID'] == id, 'ANX'].tolist() if v != -4]\n",
    "                # nacctbi_values = [v for v in uds_df.loc[uds_df['NACCID'] == id, 'NACCTBI'].tolist() if v != -4]\n",
    "                anymeds_values = [v for v in uds_df.loc[uds_df['NACCID'] == id, 'ANYMEDS'].tolist() if v != -4]\n",
    "                # Store the most frequent value in the dictionaries\n",
    "                anymeds_vectors[id] = max(set(anymeds_values), key=anymeds_values.count) if anymeds_values else 0\n",
    "                \n",
    "                # naccfam_vectors[id] = max(set(naccfam_values), key=naccfam_values.count) if naccfam_values else 0\n",
    "                # cvhatt_vectors[id] = max(set(cvhatt_values), key=cvhatt_values.count) if cvhatt_values else 0\n",
    "                # cvafib_vectors[id] = max(set(cvafib_values), key=cvafib_values.count) if cvafib_values else 0\n",
    "                # diabetes_vectors[id] = max(set(diabetes_values), key=diabetes_values.count) if diabetes_values else 0\n",
    "                # hypercho_vectors[id] = max(set(hypercho_values), key=hypercho_values.count) if hypercho_values else 0\n",
    "                # hyperten_vectors[id] = max(set(hyperten_values), key=hyperten_values.count) if hyperten_values else 0\n",
    "                # b12def_vectors[id] = max(set(b12def_values), key=b12def_values.count) if b12def_values else 0\n",
    "                # depd_vectors[id] = max(set(depd_values), key=depd_values.count) if depd_values else 0\n",
    "                # anx_vectors[id] = max(set(anx_values), key=anx_values.count) if anx_values else 0\n",
    "                # nacctbi_vectors[id] = max(set(nacctbi_values), key=nacctbi_values.count) if nacctbi_values else 0\n",
    "                \n",
    "            # Add new columns to the test_df DataFrame\n",
    "            test_df['ANYMEDS'] = test_df['ID'].apply(lambda x: anymeds_vectors[x])\n",
    "            # test_df['NACCFAM'] = test_df['ID'].apply(lambda x: naccfam_vectors[x])\n",
    "            # test_df['CVHATT'] = test_df['ID'].apply(lambda x: cvhatt_vectors[x])\n",
    "            # test_df['CVAFIB'] = test_df['ID'].apply(lambda x: cvafib_vectors[x])\n",
    "            # test_df['DIABETES'] = test_df['ID'].apply(lambda x: diabetes_vectors[x])\n",
    "            # test_df['HYPERCHO'] = test_df['ID'].apply(lambda x: hypercho_vectors[x])\n",
    "            # test_df['HYPERTEN'] = test_df['ID'].apply(lambda x: hyperten_vectors[x])\n",
    "            # test_df['B12DEF'] = test_df['ID'].apply(lambda x: b12def_vectors[x])\n",
    "            # test_df['DEPD'] = test_df['ID'].apply(lambda x: depd_vectors[x])\n",
    "            # test_df['ANX'] = test_df['ID'].apply(lambda x: anx_vectors[x])\n",
    "            # test_df['NACCTBI'] = test_df['ID'].apply(lambda x: nacctbi_vectors[x])\n",
    "            \n",
    "            # Print the updated DataFrame to verify\n",
    "            print(f\"Updated DataFrame for {file}:\")\n",
    "            print(test_df.head())\n",
    "            \n",
    "            # Optionally, save the updated DataFrame back to CSV\n",
    "            test_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts_dir = 'Cohorts'\n",
    "for root, dirs, files in os.walk(cohorts_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            test_df = pd.read_csv(file_path)\n",
    "            \n",
    "            # smokyrs_vectors = {}\n",
    "            # race_vectors = {}\n",
    "            hearing_vectors = {}\n",
    "            hearaid_vectors = {}\n",
    "            hearwaid_vectors = {}\n",
    "            vision_vectors = {}\n",
    "            viscorr_vectors = {}\n",
    "            viswcorr_vectors = {}\n",
    "            \n",
    "            uds_df = pd.read_csv('uds.csv')\n",
    "            # Iterate through each unique ID in the uds_df\n",
    "            for id in test_df['ID'].unique():\n",
    "                hearing_values = uds_df.loc[uds_df['NACCID'] == id, 'HEARING'].tolist()\n",
    "                hearaid_values = uds_df.loc[uds_df['NACCID'] == id, 'HEARAID'].tolist()\n",
    "                hearwaid_values = uds_df.loc[uds_df['NACCID'] == id, 'HEARWAID'].tolist()\n",
    "                vision_values = uds_df.loc[uds_df['NACCID'] == id, 'VISION'].tolist()\n",
    "                viscorr_values = uds_df.loc[uds_df['NACCID'] == id, 'VISCORR'].tolist()\n",
    "                viswcorr_values = uds_df.loc[uds_df['NACCID'] == id, 'VISWCORR'].tolist()\n",
    "                hearing_vectors[id] = hearing_values\n",
    "                hearaid_vectors[id] = hearaid_values\n",
    "                hearwaid_vectors[id] = hearwaid_values\n",
    "                vision_vectors[id] = vision_values\n",
    "                viscorr_vectors[id] = viscorr_values\n",
    "                viswcorr_vectors[id] = viswcorr_values\n",
    "                \n",
    "                # Get the values for the current ID\n",
    "                # smokyrs_values = uds_df.loc[uds_df['NACCID'] == id, 'SMOKYRS'].tolist()\n",
    "                # Note here is where the previous repeated vars were. \n",
    "                # Store the values in the dictionary\n",
    "                # smokyrs_vectors[id] = smokyrs_values\n",
    "            #     race_values = uds_df.loc[uds_df['NACCID'] == id, 'RACE'].tolist()\n",
    "            #     race_vectors[id] = race_values\n",
    "            # test_df['RACE'] = test_df['ID'].apply(lambda x: max(race_vectors[x]) if race_vectors[x] else np.nan)                 \n",
    "               \n",
    "               \n",
    "                \n",
    "            # Add new columns to the test_df DataFrame\n",
    "            # if 'SMOKYRS' in test_df.columns:\n",
    "            #     # drop the existing column\n",
    "            #     test_df.drop('SMOKYRS', axis=1, inplace=True)\n",
    "            #     test_df['SMOKYRS'] = test_df['ID'].apply(lambda x: max(smokyrs_vectors[x]) if smokyrs_vectors[x] else np.nan)\n",
    "            # else:\n",
    "            #     test_df['SMOKYRS'] = test_df['ID'].apply(lambda x: max(smokyrs_vectors[x]) if smokyrs_vectors[x] else np.nan)\n",
    "            # test_df['GDS'] = test_df['ID'].apply(lambda x: gds_vectors[x])\n",
    "            # test_df['CDR'] = test_df['ID'].apply(lambda x: cdr_vectors[x])\n",
    "            # test_df['TOBAC30'] = test_df['ID'].apply(lambda x: tobac_vectors[x])\n",
    "            # test_df['BILLS'] = test_df['ID'].apply(lambda x: bills_vectors[x])\n",
    "            # test_df['TAXES'] = test_df['ID'].apply(lambda x: taxes_vectors[x])\n",
    "            # test_df['SHOPPING'] = test_df['ID'].apply(lambda x: shopping_vectors[x])\n",
    "            # test_df['GAMES'] = test_df['ID'].apply(lambda x: games_vectors[x])\n",
    "            # test_df['STOVE'] = test_df['ID'].apply(lambda x: stove_vectors[x])\n",
    "            # test_df['MEALPREP'] = test_df['ID'].apply(lambda x: mealprep_vectors[x])\n",
    "            # test_df['EVENTS'] = test_df['ID'].apply(lambda x: events_vectors[x])\n",
    "            # test_df['PAYATTN'] = test_df['ID'].apply(lambda x: payattn_vectors[x])\n",
    "            # test_df['REMDATES'] = test_df['ID'].apply(lambda x: remdates_vectors[x])\n",
    "            # test_df['TRAVEL'] = test_df['ID'].apply(lambda x: travel_vectors[x])\n",
    "            test_df['HEARING'] = test_df['ID'].apply(lambda x: hearing_vectors[x])\n",
    "            test_df['HEARAID'] = test_df['ID'].apply(lambda x: hearaid_vectors[x])\n",
    "            test_df['HEARWAID'] = test_df['ID'].apply(lambda x: hearwaid_vectors[x])\n",
    "            test_df['VISION'] = test_df['ID'].apply(lambda x: vision_vectors[x])\n",
    "            test_df['VISCORR'] = test_df['ID'].apply(lambda x: viscorr_vectors[x])\n",
    "            test_df['VISWCORR'] = test_df['ID'].apply(lambda x: viswcorr_vectors[x])\n",
    "            \n",
    "            # Print the updated DataFrame to verify\n",
    "            print(f\"Updated DataFrame for {file}:\")\n",
    "            print(test_df.head())\n",
    "            \n",
    "            # Optionally, save the updated DataFrame back to CSV\n",
    "            test_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recoding comorbidities to binary, remote/inactive and unknown are getting recoded to 0: Absent\n",
    "\n",
    "Original stats: {'0': 111400, '1': 28443, '2': 2073, '9': 2094, '-4': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 115567, '1': 28443}\n"
     ]
    }
   ],
   "source": [
    "cohorts_dir = 'Cohorts'\n",
    "response_counts = {'0': 0, '1': 0}\n",
    "\n",
    "for root, dirs, files in os.walk(cohorts_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            comorbidities = df.iloc[:, 22:32]\n",
    "            \n",
    "            for index, row in comorbidities.iterrows():\n",
    "                for col in row.index:\n",
    "                    value = row[col]\n",
    "                    if value in [2, 9, -4]:\n",
    "                        df.at[index, col] = 0\n",
    "                    elif value == 1:\n",
    "                        df.at[index, col] = 1\n",
    "                    else:\n",
    "                        df.at[index, col] = 0\n",
    "                    response_counts[str(df.at[index, col])] += 1\n",
    "            cohorts_dir\n",
    "            # Save the updated DataFrame back to CSV\n",
    "            df.to_csv(file_path, index=False)\n",
    "\n",
    "print(response_counts)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts_dir = 'Cohorts'\n",
    "response_counts = {'0': 0, '1': 0, '2': 0, '9': 0, '-4': 0}\n",
    "\n",
    "for root, dirs, files in os.walk(cohorts_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            comorbidities = df.iloc[:, 22:32]\n",
    "            \n",
    "            for index, row in comorbidities.iterrows():\n",
    "                for col in row.index:\n",
    "                    value = row[col]\n",
    "                    response_counts[str(value)] += 1\n",
    "\n",
    "print(response_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
