{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique IDs: 3305\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import ast\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = 'Cohorts\\\\NonProgressors\\\\2visit_nonprogressor.csv'\n",
    "\n",
    "# Set to store unique IDs\n",
    "unique_ids = set()\n",
    "\n",
    "# Read the CSV file\n",
    "with open(file_path, mode='r', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip the header\n",
    "    for row in reader:\n",
    "        ids_list = ast.literal_eval(row[0])\n",
    "        unique_ids.update(ids_list)\n",
    "\n",
    "# Print the number of unique IDs\n",
    "print(f\"Number of unique IDs: {len(unique_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use above to verify the counts after fixing the csvs to be all in one row. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def combine_ids_to_one_row(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path, header=0)\n",
    "            \n",
    "            # Combine all IDs into a single row\n",
    "            all_ids = []\n",
    "            for ids in df['NACCID']:\n",
    "                ids_list = eval(ids) if isinstance(ids, str) else ids\n",
    "                all_ids.extend(ids_list)\n",
    "            \n",
    "            # Create a new DataFrame with a single row of combined IDs\n",
    "            combined_df = pd.DataFrame({'NACCID': [str(all_ids)]})\n",
    "            \n",
    "            # Save the updated DataFrame back to the CSV file\n",
    "            combined_df.to_csv(file_path, index=False)\n",
    "\n",
    "# Specify the folder path containing the CSV files\n",
    "folder_path = 'c:/Users/Andrew/Desktop/AGE/Cohorts'\n",
    "combine_ids_to_one_row(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-27 Below is an example of the multiindex dataframe that I am going to be modeling after. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Prog_ID  Progression\n",
      "ID         Visit                      \n",
      "NACC973112 1            0            0\n",
      "           2            0            0\n",
      "NACC993141 1            1            0\n",
      "           2            1            1\n",
      "NACC063570 1            0            0\n",
      "           2            0            0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "ids = ['NACC973112', 'NACC993141', 'NACC063570']\n",
    "labels = [0, 1, 0]\n",
    "vectors = [[0, 0], [0, 1], [0, 0]]\n",
    "\n",
    "# Create a MultiIndex DataFrame\n",
    "data = []\n",
    "for id, label, vector in zip(ids, labels, vectors):\n",
    "    for visit, value in enumerate(vector, start=1):\n",
    "        data.append((id, visit, label, value))\n",
    "\n",
    "df_combined = pd.DataFrame(data, columns=['ID', 'Visit', 'Prog_ID', 'Progression'])\n",
    "\n",
    "# Set MultiIndex\n",
    "df_combined.set_index(['ID', 'Visit'], inplace=True)\n",
    "\n",
    "# Print the DataFrame to verify\n",
    "print(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_10visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_11visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_12visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_13visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_14visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_15visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_16visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_17visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_18visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_19visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_20visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_2visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_3visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_4visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_5visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_6visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_7visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_8visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/Progressors\\cleaned_9visit_progressors.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_10visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_11visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_12visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_13visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_14visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_15visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_16visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_17visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_18visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_19visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_20visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_2visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_3visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_4visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_5visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_6visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_7visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_8visit_nonprogressor.csv\n",
      "Cleaned file saved to: Cohorts/NonProgressors\\cleaned_9visit_nonprogressor.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Function to clean and parse the CSV file\n",
    "def clean_and_parse_csv(file_path):\n",
    "    ids = []\n",
    "    vectors = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        next(file)  # Skip the header\n",
    "        for line in file:\n",
    "            if line.startswith('\"['):\n",
    "                # Extract and clean the NACCIDs\n",
    "                id_str = line.split('\",\"')[0].strip().strip('\"').strip('[]').replace(\"'\", \"\")\n",
    "                id_list = id_str.split(\", \")\n",
    "                ids.extend(id_list)\n",
    "                \n",
    "                # Extract and clean the ProgressionVector\n",
    "                vector_str = line.split('\",\"')[1].strip().strip('\"').strip('[]')\n",
    "                vector = ast.literal_eval(vector_str)\n",
    "                vectors.extend([vector] * len(id_list))\n",
    "    \n",
    "    # Create a DataFrame with cleaned data\n",
    "    df = pd.DataFrame({'NACCID': ids, 'ProgressionVector': vectors})\n",
    "    return df\n",
    "\n",
    "def clean_all_csv_files_in_directory(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            df_cleaned = clean_and_parse_csv(file_path)\n",
    "            cleaned_file_path = os.path.join(directory, f\"cleaned_{filename}\")\n",
    "            df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "            print(f\"Cleaned file saved to: {cleaned_file_path}\")\n",
    "\n",
    "# Clean all CSV files in the Progressors and NonProgressors directories\n",
    "clean_all_csv_files_in_directory('Cohorts/Progressors')\n",
    "clean_all_csv_files_in_directory('Cohorts/NonProgressors')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
