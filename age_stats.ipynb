{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find the age distribution for each of the categories. (how many in 55-60,61-70,71-80,81-90+) NOTE: only worry about 2 visits - 5 visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# import matplotlib.pyplot as plt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lz000\\OneDrive\\Older Account\\Desktop\\AGE-ADAR\\.venv\\Lib\\site-packages\\pandas\\__init__.py:134\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m offsets\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28meval\u001b[39m\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    135\u001b[0m     concat,\n\u001b[0;32m    136\u001b[0m     lreshape,\n\u001b[0;32m    137\u001b[0m     melt,\n\u001b[0;32m    138\u001b[0m     wide_to_long,\n\u001b[0;32m    139\u001b[0m     merge,\n\u001b[0;32m    140\u001b[0m     merge_asof,\n\u001b[0;32m    141\u001b[0m     merge_ordered,\n\u001b[0;32m    142\u001b[0m     crosstab,\n\u001b[0;32m    143\u001b[0m     pivot,\n\u001b[0;32m    144\u001b[0m     pivot_table,\n\u001b[0;32m    145\u001b[0m     get_dummies,\n\u001b[0;32m    146\u001b[0m     from_dummies,\n\u001b[0;32m    147\u001b[0m     cut,\n\u001b[0;32m    148\u001b[0m     qcut,\n\u001b[0;32m    149\u001b[0m )\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1322\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1262\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1555\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1529\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1628\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:152\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('uds.csv', header=0)\n",
    "\n",
    "np2_df = pd.read_csv('Cohorts/2visit_nonprogressor.csv',header=None)\n",
    "p2_df = pd.read_csv('Cohorts/2visit_progressors.csv',header=None)\n",
    "np3_df = pd.read_csv('Cohorts/3visit_nonprogressor.csv',header=None)\n",
    "p3_df = pd.read_csv('Cohorts/3visit_progressors.csv',header=None)\n",
    "np4_df = pd.read_csv('Cohorts/4visit_nonprogressor.csv',header=None)\n",
    "p4_df = pd.read_csv('Cohorts/4visit_progressors.csv',header=None)\n",
    "np5_df = pd.read_csv('Cohorts/5visit_nonprogressor.csv',header=None)\n",
    "p5_df = pd.read_csv('Cohorts/5visit_progressors.csv',header=None)\n",
    "np6_df = pd.read_csv('Cohorts/6visit_nonprogressor.csv',header=None)\n",
    "p6_df = pd.read_csv('Cohorts/6visit_progressors.csv',header=None)\n",
    "np7_df = pd.read_csv('Cohorts/7visit_nonprogressor.csv',header=None)\n",
    "p7_df = pd.read_csv('Cohorts/7visit_progressors.csv',header=None)\n",
    "np8_df = pd.read_csv('Cohorts/8visit_nonprogressor.csv',header=None)\n",
    "p8_df = pd.read_csv('Cohorts/8visit_progressors.csv',header=None)\n",
    "np9_df = pd.read_csv('Cohorts/9visit_nonprogressor.csv',header=None)\n",
    "p9_df = pd.read_csv('Cohorts/9visit_progressors.csv',header=None)\n",
    "np10_df = pd.read_csv('Cohorts/10visit_nonprogressor.csv',header=None)\n",
    "p10_df = pd.read_csv('Cohorts/10visit_progressors.csv',header=None)\n",
    "# initial_age = 'NACCAGEB' # or use column #747\n",
    "\n",
    "# age categories\n",
    "age51 = 0 # 51-60\n",
    "age61 = 0\n",
    "age71 = 0\n",
    "age81 = 0 # 81 and 81+\n",
    "age50 = 0 # under 51\n",
    "\n",
    "def reset_age():\n",
    "    global age50, age51, age61, age71, age81\n",
    "    age50 = 0\n",
    "    age61 = 0\n",
    "    age71 = 0\n",
    "    age81 = 0\n",
    "    age51 = 0\n",
    "\n",
    "def print_age():\n",
    "    print(\"age under 51: \"+ str(age50)\n",
    "          +\"\\nage [51,60]:  \"+str(age51)\n",
    "          +\"\\nage [61,70]:  \"+str(age61)\n",
    "          +\"\\nage [71,80]:  \"+str(age71)\n",
    "          +\"\\nage above 80: \"+str(age81))\n",
    "    \n",
    "# convert a long string to a list\n",
    "np2=ast.literal_eval(np2_df.iat[1,0])\n",
    "p2= ast.literal_eval(p2_df.iat[1,0]) \n",
    "np3= ast.literal_eval(np3_df.iat[1,0])\n",
    "p3= ast.literal_eval(p3_df.iat[1,0])\n",
    "np4= ast.literal_eval(np4_df.iat[1,0])\n",
    "p4= ast.literal_eval(p4_df.iat[1,0])\n",
    "np5= ast.literal_eval(np5_df.iat[1,0])\n",
    "p5= ast.literal_eval(p5_df.iat[1,0])\n",
    "np6 = ast.literal_eval(np6_df.iat[1, 0])\n",
    "p6 = ast.literal_eval(p6_df.iat[1, 0])\n",
    "np7 = ast.literal_eval(np7_df.iat[1, 0])\n",
    "p7 = ast.literal_eval(p7_df.iat[1, 0])\n",
    "np8 = ast.literal_eval(np8_df.iat[1, 0])\n",
    "p8 = ast.literal_eval(p8_df.iat[1, 0])\n",
    "np9 = ast.literal_eval(np9_df.iat[1, 0])\n",
    "p9 = ast.literal_eval(p9_df.iat[1, 0])\n",
    "np10 = ast.literal_eval(np10_df.iat[1, 0])\n",
    "p10 = ast.literal_eval(p10_df.iat[1, 0])\n",
    "\n",
    "def find_age(list):\n",
    "    global age50, age51, age61, age71, age81\n",
    "    for i in list:\n",
    "        age=int(df[df['NACCID']==i].iat[0,747])\n",
    "        if age<51:\n",
    "            age50+=1\n",
    "        elif age<61:\n",
    "            age51+=1\n",
    "        elif age<71:\n",
    "            age61+=1\n",
    "        elif age<81:\n",
    "            age71+=1\n",
    "        else: age81+=1\n",
    "\n",
    "find_age(np2)\n",
    "print(\"\\n2visit_Nonprogressor:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(p2)\n",
    "print(\"\\n2visit_progressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(np3)\n",
    "print(\"\\n3visit_Nonprogressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(p3)\n",
    "print(\"\\n3visit_progressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(np4)\n",
    "print(\"\\n4visit_Nonprogressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(p4)\n",
    "print(\"\\n4visit_progressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(np5)\n",
    "print(\"\\n5visit_Nonprogressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(p5)\n",
    "print(\"\\n5visit_progressors:\\n\")\n",
    "print_age()\n",
    "\n",
    "find_age(np6)\n",
    "print(\"\\n6visit_Nonprogressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(p6)\n",
    "print(\"\\n6visit_progressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(np7)\n",
    "print(\"\\n7visit_Nonprogressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(p7)\n",
    "print(\"\\n7visit_progressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(np8)\n",
    "print(\"\\n8visit_Nonprogressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(p8)\n",
    "print(\"\\n8visit_progressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(np9)\n",
    "print(\"\\n9visit_Nonprogressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(p9)\n",
    "print(\"\\n9visit_progressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(np10)\n",
    "print(\"\\n10visit_Nonprogressors:\\n\")\n",
    "print_age()\n",
    "reset_age()\n",
    "\n",
    "find_age(p10)\n",
    "print(\"\\n10visit_progressors:\\n\")\n",
    "print_age()\n",
    "reset_age()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the avg time between visits again for 2 visits to 5 visits. I want to see that we can use these time steps as roughly a 12 month interval but it is possible we will have to throw some out if they mess this up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\AppData\\Local\\Temp\\ipykernel_13724\\3783543766.py:5: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('uds.csv', header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg interval for 2visit_Nonprogressor: 15.300376647834275\n",
      "avg interval for 2visit_progressor: 17.78937048503612\n",
      "323\n",
      "\n",
      "avg interval for 3visit_Nonprogressor: 14.947960992907802\n",
      "376\n",
      "avg interval for 3visit_progressor: 15.950054644808743\n",
      "\n",
      "avg interval for 4visit_Nonprogressor: 15.12822477650064\n",
      "avg interval for 4visit_progressor: 15.347501032631145\n",
      "\n",
      "avg interval for 5visit_Nonprogressor: 14.082857142857142\n",
      "avg interval for 5visit_progressor: 14.71949233716475\n",
      "\n",
      "avg interval for 6visit_Nonprogressor: 15.748205128205127\n",
      "avg interval for 6visit_progressor: 14.549398907103825\n",
      "\n",
      "avg interval for 7visit_Nonprogressor: 15.82685185185185\n",
      "avg interval for 7visit_progressor: 14.110601427115188\n",
      "\n",
      "avg interval for 8visit_Nonprogressor: 14.168253968253968\n",
      "avg interval for 8visit_progressor: 13.968849206349207\n",
      "\n",
      "avg interval for 9visit_Nonprogressor: 13.511111111111111\n",
      "avg interval for 9visit_progressor: 13.990221088435373\n",
      "\n",
      "avg interval for 10visit_Nonprogressor: 13.481481481481483\n",
      "avg interval for 10visit_progressor: 14.120420420420421\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('investigator_nacc67.csv', header=0)\n",
    "\n",
    "np2_df = pd.read_csv('Cohorts/2visit_nonprogressor.csv',header=None)\n",
    "p2_df = pd.read_csv('Cohorts/2visit_progressors.csv',header=None)\n",
    "np3_df = pd.read_csv('Cohorts/3visit_nonprogressor.csv',header=None)\n",
    "p3_df = pd.read_csv('Cohorts/3visit_progressors.csv',header=None)\n",
    "np4_df = pd.read_csv('Cohorts/4visit_nonprogressor.csv',header=None)\n",
    "p4_df = pd.read_csv('Cohorts/4visit_progressors.csv',header=None)\n",
    "np5_df = pd.read_csv('Cohorts/5visit_nonprogressor.csv',header=None)\n",
    "p5_df = pd.read_csv('Cohorts/5visit_progressors.csv',header=None)\n",
    "np6_df = pd.read_csv('Cohorts/6visit_nonprogressor.csv',header=None)\n",
    "p6_df = pd.read_csv('Cohorts/6visit_progressors.csv',header=None)\n",
    "np7_df = pd.read_csv('Cohorts/7visit_nonprogressor.csv',header=None)\n",
    "p7_df = pd.read_csv('Cohorts/7visit_progressors.csv',header=None)\n",
    "np8_df = pd.read_csv('Cohorts/8visit_nonprogressor.csv',header=None)\n",
    "p8_df = pd.read_csv('Cohorts/8visit_progressors.csv',header=None)\n",
    "np9_df = pd.read_csv('Cohorts/9visit_nonprogressor.csv',header=None)\n",
    "p9_df = pd.read_csv('Cohorts/9visit_progressors.csv',header=None)\n",
    "np10_df = pd.read_csv('Cohorts/10visit_nonprogressor.csv',header=None)\n",
    "p10_df = pd.read_csv('Cohorts/10visit_progressors.csv',header=None)\n",
    "\n",
    "# days_from_initial_visit_to_this_visit= 'NACCFDYS' # or use column #11\n",
    "\n",
    "np2=ast.literal_eval(np2_df.iat[1,0])\n",
    "p2= ast.literal_eval(p2_df.iat[1,0]) \n",
    "np3= ast.literal_eval(np3_df.iat[1,0])\n",
    "p3= ast.literal_eval(p3_df.iat[1,0])\n",
    "np4= ast.literal_eval(np4_df.iat[1,0])\n",
    "p4= ast.literal_eval(p4_df.iat[1,0])\n",
    "np5= ast.literal_eval(np5_df.iat[1,0])\n",
    "p5= ast.literal_eval(p5_df.iat[1,0])\n",
    "np6 = ast.literal_eval(np6_df.iat[1, 0])\n",
    "p6 = ast.literal_eval(p6_df.iat[1, 0])\n",
    "np7 = ast.literal_eval(np7_df.iat[1, 0])\n",
    "p7 = ast.literal_eval(p7_df.iat[1, 0])\n",
    "np8 = ast.literal_eval(np8_df.iat[1, 0])\n",
    "p8 = ast.literal_eval(p8_df.iat[1, 0])\n",
    "np9 = ast.literal_eval(np9_df.iat[1, 0])\n",
    "p9 = ast.literal_eval(p9_df.iat[1, 0])\n",
    "np10 = ast.literal_eval(np10_df.iat[1, 0])\n",
    "p10 = ast.literal_eval(p10_df.iat[1, 0])\n",
    "\n",
    "\n",
    "avg = 0\n",
    "count = 0\n",
    "\n",
    "def reset():\n",
    "    global avg, count\n",
    "    avg=0\n",
    "    count=0\n",
    "\n",
    "def find_interval(list):\n",
    "    global avg, count\n",
    "    for i in list:\n",
    "        match=df[df['NACCID']==i]\n",
    "        match=match.sort_values(by=match.columns[11])\n",
    "        for j in range(1,len(match)):\n",
    "            avg+= (int(match.iat[j,11])-int(match.iat[j-1,11]))\n",
    "            count+=1\n",
    "\n",
    "find_interval(np2)\n",
    "print(\"avg interval for 2visit_Nonprogressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(p2)\n",
    "print(\"avg interval for 2visit_progressor: \"+str(avg/count/30.0))\n",
    "print(count)\n",
    "reset()\n",
    "find_interval(np3)\n",
    "print(\"\\navg interval for 3visit_Nonprogressor: \"+str(avg/count/30.0))\n",
    "print(count)\n",
    "reset()\n",
    "find_interval(p3)\n",
    "print(\"avg interval for 3visit_progressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(np4)\n",
    "print(\"\\navg interval for 4visit_Nonprogressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(p4)\n",
    "print(\"avg interval for 4visit_progressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(np5)\n",
    "print(\"\\navg interval for 5visit_Nonprogressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(p5)\n",
    "print(\"avg interval for 5visit_progressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(np6)\n",
    "print(\"\\navg interval for 6visit_Nonprogressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(p6)\n",
    "print(\"avg interval for 6visit_progressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(np7)\n",
    "print(\"\\navg interval for 7visit_Nonprogressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(p7)\n",
    "print(\"avg interval for 7visit_progressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(np8)\n",
    "print(\"\\navg interval for 8visit_Nonprogressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(p8)\n",
    "print(\"avg interval for 8visit_progressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(np9)\n",
    "print(\"\\navg interval for 9visit_Nonprogressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(p9)\n",
    "print(\"avg interval for 9visit_progressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(np10)\n",
    "print(\"\\navg interval for 10visit_Nonprogressor: \"+str(avg/count/30.0))\n",
    "reset()\n",
    "find_interval(p10)\n",
    "print(\"avg interval for 10visit_progressor: \"+str(avg/count/30.0))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate average time interval between visits for each visit count group. Also individual # belongs to each subgroup (CN CN-MCI, MCI, MCI-AD) within each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 2 visits group:\n",
      "CN = 1044\n",
      "CN_MCI = 81\n",
      "MCI = 221\n",
      "MCI_AD = 220\n",
      "For 3 visits group:\n",
      "CN = 572\n",
      "CN_MCI = 49\n",
      "MCI = 85\n",
      "MCI_AD = 213\n",
      "For 4 visits group:\n",
      "CN = 551\n",
      "CN_MCI = 37\n",
      "MCI = 36\n",
      "MCI_AD = 205\n",
      "For 5 visits group:\n",
      "CN = 424\n",
      "CN_MCI = 22\n",
      "MCI = 11\n",
      "MCI_AD = 127\n",
      "3898\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# find # count for each subgroup and interval for the whole visit count group\n",
    "def stat(visit_num):\n",
    "    global sum\n",
    "    cn= 0\n",
    "    cn_mci= 0\n",
    "    mci= 0\n",
    "    mci_ad = 0\n",
    "    file_path_CN = 'AD-Early-Prediction/Dataset_1/' + str(visit_num) + 'visit_CN_MCI.csv'\n",
    "    file_path_MCI = 'AD-Early-Prediction/Dataset_1/' + str(visit_num) + 'visit_MCI_AD.csv'\n",
    "    csv_cn=pd.read_csv(file_path_CN)\n",
    "    csv_mci=pd.read_csv(file_path_MCI)\n",
    "\n",
    "    # create lists to store IDs for time interval calc\n",
    "    l = list()\n",
    "\n",
    "    # split IDs into two groups based on progressor status\n",
    "    for i in range(0, len(csv_cn)):\n",
    "        l.append(csv_cn.iloc[i,0])\n",
    "        if (csv_cn.iloc[i,1]==0):\n",
    "            cn_list.append(csv_cn.iloc[i,0])\n",
    "            cn+=1\n",
    "        else: \n",
    "            cn_mci_list.append(csv_cn.iloc[i,0])\n",
    "            cn_mci+=1\n",
    "\n",
    "    for i in range(0, len(csv_mci)):\n",
    "        l.append(csv_mci.iloc[i,0])\n",
    "        if (csv_mci.iloc[i,1]==0):\n",
    "            mci_list.append(csv_mci.iloc[i,0])\n",
    "            mci+=1\n",
    "        else: \n",
    "            mci_ad_list.append(csv_mci.iloc[i,0])\n",
    "            mci_ad+=1\n",
    "\n",
    "    print('For '+ str(visit_num)+' visits group:')\n",
    "    print('CN = '+str(cn))\n",
    "    print('CN_MCI = '+str(cn_mci))\n",
    "    print('MCI = '+str(mci))\n",
    "    print('MCI_AD = '+str(mci_ad))\n",
    "\n",
    "    sum = cn + cn_mci + mci + mci_ad + sum\n",
    "    # find_interval(l)\n",
    "\n",
    "def find_interval(list):\n",
    "    avg=0\n",
    "    count=0\n",
    "    for i in list:\n",
    "        match=df[df['NACCID']==i]\n",
    "        match=match.sort_values(by=match.columns[11])\n",
    "        for j in range(1,len(match)):\n",
    "            avg+= (int(match.iat[j,11])-int(match.iat[j-1,11]))\n",
    "            count+=1\n",
    "\n",
    "    print('time interval = '+ str(avg/count/30.0)+'months\\n')\n",
    "\n",
    "# main lines\n",
    "\n",
    "# df = pd.read_csv('investigator_nacc67.csv', header=0)\n",
    "\n",
    "cn_list= list()\n",
    "cn_mci_list= list()\n",
    "mci_list= list()\n",
    "mci_ad_list= list()\n",
    "\n",
    "# all individuals count\n",
    "sum = 0\n",
    "\n",
    "for a in range(2,6):\n",
    "    stat(a)\n",
    "\n",
    "# save each group's ID list as text files\n",
    "with open(\"CN_list.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(cn_list))\n",
    "\n",
    "with open(\"CN_MCI_list.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(cn_mci_list))\n",
    "\n",
    "with open(\"MCI_list.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(mci_list))\n",
    "\n",
    "with open(\"MCI_AD_list.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(mci_ad_list))\n",
    "\n",
    "print(sum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demographic Statistics\n",
    "4 columns, again, Stable CN, CN to MCI, Stable MCI, MCI to AD\n",
    "AGE\n",
    "SEX\n",
    "RACE\n",
    "COMORNIDITIES\n",
    "    ALCOHOL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN: 2591\n",
      "CN_MCI: 189\n",
      "MCI: 353\n",
      "MCI_AD: 765\n",
      "\n",
      "\n",
      "CN group stats:\n",
      "average age: 70.61868004631417\n",
      "     51-60:  319  |  12.3%\n",
      "     61-70:  859  |  33.2%\n",
      "     71-80:  836  |  32.3%\n",
      "     81-90:  435  |  16.8%\n",
      "Male:  856  |  33.0%\n",
      "Female:  1735  |  67.0%\n",
      "     White:  2034  |  78.5%\n",
      "     Black:  453  |  17.5%\n",
      "     American Indians:  21  |  0.8%\n",
      "     Native Hawaiian:  1  |  0.0%\n",
      "     Asian:  67  |  2.6%\n",
      "     Other:  15  |  0.6%\n",
      "     Hispanic/Latino:  158  |  6.1%\n",
      "     Not Hispanic/Latino:  2433  |  93.9%\n",
      "Alcohol:  13  |  0.5%\n",
      "Heart attack:  20  |  0.8%\n",
      "Atrial fibrillation:  151  |  5.8%\n",
      "Diabetes:  321  |  12.4%\n",
      "Hypercholesterolemia:  1264  |  48.8%\n",
      "Hypertension:  1367  |  52.8%\n",
      "Vitamin B12 deficiency:  73  |  2.8%\n",
      "Depression:  177  |  6.8%\n",
      "Anxiety:  95  |  3.7%\n",
      "History of traumatic brain injury:  253  |  9.8%\n",
      "\n",
      "CN_MCI group stats:\n",
      "average age: 74.4920634920635\n",
      "     51-60:  10  |  5.3%\n",
      "     61-70:  48  |  25.4%\n",
      "     71-80:  78  |  41.3%\n",
      "     81-90:  44  |  23.3%\n",
      "Male:  85  |  45.0%\n",
      "Female:  104  |  55.0%\n",
      "     White:  148  |  78.3%\n",
      "     Black:  33  |  17.5%\n",
      "     American Indians:  1  |  0.5%\n",
      "     Native Hawaiian:  0  |  0.0%\n",
      "     Asian:  3  |  1.6%\n",
      "     Other:  4  |  2.1%\n",
      "     Hispanic/Latino:  11  |  5.8%\n",
      "     Not Hispanic/Latino:  178  |  94.2%\n",
      "Alcohol:  0  |  0.0%\n",
      "Heart attack:  2  |  1.1%\n",
      "Atrial fibrillation:  16  |  8.5%\n",
      "Diabetes:  36  |  19.0%\n",
      "Hypercholesterolemia:  97  |  51.3%\n",
      "Hypertension:  107  |  56.6%\n",
      "Vitamin B12 deficiency:  8  |  4.2%\n",
      "Depression:  28  |  14.8%\n",
      "Anxiety:  16  |  8.5%\n",
      "History of traumatic brain injury:  21  |  11.1%\n",
      "\n",
      "MCI group stats:\n",
      "average age: 71.11614730878188\n",
      "     51-60:  40  |  11.3%\n",
      "     61-70:  120  |  34.0%\n",
      "     71-80:  137  |  38.8%\n",
      "     81-90:  46  |  13.0%\n",
      "Male:  181  |  51.3%\n",
      "Female:  172  |  48.7%\n",
      "     White:  253  |  71.7%\n",
      "     Black:  73  |  20.7%\n",
      "     American Indians:  8  |  2.3%\n",
      "     Native Hawaiian:  0  |  0.0%\n",
      "     Asian:  9  |  2.5%\n",
      "     Other:  10  |  2.8%\n",
      "     Hispanic/Latino:  32  |  9.1%\n",
      "     Not Hispanic/Latino:  321  |  90.9%\n",
      "Alcohol:  4  |  1.1%\n",
      "Heart attack:  1  |  0.3%\n",
      "Atrial fibrillation:  12  |  3.4%\n",
      "Diabetes:  64  |  18.1%\n",
      "Hypercholesterolemia:  191  |  54.1%\n",
      "Hypertension:  203  |  57.5%\n",
      "Vitamin B12 deficiency:  13  |  3.7%\n",
      "Depression:  85  |  24.1%\n",
      "Anxiety:  33  |  9.3%\n",
      "History of traumatic brain injury:  46  |  13.0%\n",
      "\n",
      "MCI_AD group stats:\n",
      "average age: 76.04313725490196\n",
      "     51-60:  30  |  3.9%\n",
      "     61-70:  154  |  20.1%\n",
      "     71-80:  335  |  43.8%\n",
      "     81-90:  209  |  27.3%\n",
      "Male:  373  |  48.8%\n",
      "Female:  392  |  51.2%\n",
      "     White:  640  |  83.7%\n",
      "     Black:  96  |  12.5%\n",
      "     American Indians:  7  |  0.9%\n",
      "     Native Hawaiian:  0  |  0.0%\n",
      "     Asian:  7  |  0.9%\n",
      "     Other:  15  |  2.0%\n",
      "     Hispanic/Latino:  61  |  8.0%\n",
      "     Not Hispanic/Latino:  704  |  92.0%\n",
      "Alcohol:  10  |  1.3%\n",
      "Heart attack:  9  |  1.2%\n",
      "Atrial fibrillation:  57  |  7.5%\n",
      "Diabetes:  111  |  14.5%\n",
      "Hypercholesterolemia:  429  |  56.1%\n",
      "Hypertension:  436  |  57.0%\n",
      "Vitamin B12 deficiency:  32  |  4.2%\n",
      "Depression:  183  |  23.9%\n",
      "Anxiety:  128  |  16.7%\n",
      "History of traumatic brain injury:  68  |  8.9%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import math\n",
    "\n",
    "# Gives column total individual counts\n",
    "with open(\"CN_list.txt\", \"r\") as file:\n",
    "    CN_list = file.read().splitlines()  # Splits the file content into lines\n",
    "print('CN: '+ str(len(CN_list)))\n",
    "\n",
    "with open(\"CN_MCI_list.txt\", \"r\") as file:\n",
    "    CN_MCI_list = file.read().splitlines()  # Splits the file content into lines\n",
    "print('CN_MCI: '+ str(len(CN_MCI_list)))\n",
    "\n",
    "with open(\"MCI_list.txt\", \"r\") as file:\n",
    "    MCI_list = file.read().splitlines()  # Splits the file content into lines\n",
    "print('MCI: '+ str(len(MCI_list)))\n",
    "\n",
    "with open(\"MCI_AD_list.txt\", \"r\") as file:\n",
    "    MCI_AD_list = file.read().splitlines()  # Splits the file content into lines\n",
    "print('MCI_AD: '+ str(len(MCI_AD_list))+ '\\n\\n')\n",
    "\n",
    "# format print\n",
    "def p(des, count, total):\n",
    "    print(des + ':  '+ str(count)+'  |  '+str(round(100.0*count/total, 1 ))+ '%')\n",
    "\n",
    "def find(id):\n",
    "    for a in df:\n",
    "        if not (a.loc[a['ID']==id].empty):\n",
    "            return a.loc[a['ID']==id]\n",
    "    print(\"\\nERROR--ID NOT FOUND: \"+ id + '\\n')\n",
    "\n",
    "\n",
    "def analyze(l):\n",
    "    s = len(l)\n",
    "\n",
    "    # age sum\n",
    "    a=0\n",
    "    # age groups counts\n",
    "    age51 = 0 # 51-60\n",
    "    age61 = 0\n",
    "    age71 = 0\n",
    "    age81 = 0 # 81-90\n",
    "\n",
    "    # sex\n",
    "    m = 0\n",
    "    f = 0\n",
    "\n",
    "    # RACE\n",
    "    white = 0\n",
    "    black = 0\n",
    "    ai = 0\n",
    "    nh = 0\n",
    "    asian = 0\n",
    "    other = 0\n",
    "\n",
    "    # HISPANIC\n",
    "    hispanic = 0\n",
    "    not_hispanic = 0\n",
    "\n",
    "    # comorbidities\n",
    "    alcohol = 0\n",
    "    heart_attack = 0\n",
    "    atrial_fibrillation = 0\n",
    "    diabetes = 0\n",
    "    hypercholesteromia = 0\n",
    "    hypertension = 0\n",
    "    vb12 = 0\n",
    "    depression = 0\n",
    "    anxiety = 0\n",
    "    trauma = 0\n",
    "\n",
    "    for i in l:\n",
    "        row = find(i)\n",
    "\n",
    "        # safe\n",
    "        if (row is None):\n",
    "            continue\n",
    "\n",
    "        # AGE\n",
    "        age = int(row.iloc[0]['age'])\n",
    "        a+=age\n",
    "        if age<51:\n",
    "            skip=''\n",
    "        elif age<61:\n",
    "            age51+=1\n",
    "        elif age<71:\n",
    "            age61+=1\n",
    "        elif age<81:\n",
    "            age71+=1\n",
    "        elif age<91:\n",
    "            age81+=1\n",
    "        \n",
    "        # sex\n",
    "        sex = int(row.iloc[0]['SEX'])\n",
    "        if sex==1:\n",
    "            m+=1\n",
    "        elif sex==2:\n",
    "            f+=1\n",
    "\n",
    "        # RACE\n",
    "        if not (math.isnan(row.iloc[0][\"RACE\"])):\n",
    "            race= int(row.iloc[0]['RACE'])\n",
    "            if race==1:\n",
    "                white+=1\n",
    "            elif race==2:\n",
    "                black+=1\n",
    "            elif race==3:\n",
    "                ai+=1\n",
    "            elif race==4:\n",
    "                nh+=1\n",
    "            elif race==5:\n",
    "                asian+=1\n",
    "            else: other+=1\n",
    "        else:\n",
    "            print(\"\\nwarning: \"+i+\" has a RACE value of \"+str(row.iloc[0][\"RACE\"])+ '\\n')\n",
    "\n",
    "        # HISPANIC\n",
    "        if (int(row.iloc[0]['HISPANIC'])==1):\n",
    "            hispanic+=1\n",
    "        else: not_hispanic+=1\n",
    "\n",
    "        # comorbidities\n",
    "        if (int(row.iloc[0]['ALCOHOL'])==1):\n",
    "            alcohol+=1\n",
    "    \n",
    "        if (int(row.iloc[0]['CVHATT'])==1):\n",
    "            heart_attack+=1\n",
    "    \n",
    "        if (int(row.iloc[0]['CVAFIB'])==1):\n",
    "            atrial_fibrillation+=1\n",
    "    \n",
    "        if (int(row.iloc[0]['DIABETES'])==1):\n",
    "            diabetes+=1\n",
    "    \n",
    "        if (int(row.iloc[0]['HYPERCHO'])==1):\n",
    "            hypercholesteromia+=1\n",
    "    \n",
    "        if (int(row.iloc[0]['HYPERTEN'])==1):\n",
    "            hypertension+=1\n",
    "    \n",
    "        if (int(row.iloc[0]['B12DEF'])==1):\n",
    "            vb12+=1\n",
    "    \n",
    "        if (int(row.iloc[0]['DEPD'])==1):\n",
    "            depression+=1\n",
    "    \n",
    "        if (int(row.iloc[0]['ANX'])==1):\n",
    "            anxiety+=1\n",
    "    \n",
    "        if (int(row.iloc[0]['NACCTBI'])==1):\n",
    "            trauma+=1\n",
    "\n",
    "\n",
    "    # age\n",
    "    print(\"average age: \" + str(a/s/1.0))\n",
    "    p(\"     51-60\", age51, s)\n",
    "    p(\"     61-70\", age61, s)\n",
    "    p(\"     71-80\", age71, s)\n",
    "    p(\"     81-90\", age81, s)\n",
    "\n",
    "    # sex\n",
    "    p(\"Male\", m, s)\n",
    "    p(\"Female\", f, s)\n",
    "\n",
    "    # RACE\n",
    "    p(\"     White\", white, s)\n",
    "    p(\"     Black\", black, s)\n",
    "    p(\"     American Indians\", ai, s)\n",
    "    p(\"     Native Hawaiian\", nh, s)\n",
    "    p(\"     Asian\", asian, s)\n",
    "    p(\"     Other\", other, s)\n",
    "\n",
    "    # HISPANIC\n",
    "    p(\"     Hispanic/Latino\", hispanic, s)\n",
    "    p(\"     Not Hispanic/Latino\", not_hispanic, s)\n",
    "\n",
    "    # comorbidities\n",
    "    p(\"Alcohol\", alcohol, s)\n",
    "    p(\"Heart attack\", heart_attack, s)\n",
    "    p(\"Atrial fibrillation\", atrial_fibrillation, s)\n",
    "    p(\"Diabetes\", diabetes, s)\n",
    "    p(\"Hypercholesterolemia\", hypercholesteromia, s)\n",
    "    p(\"Hypertension\", hypertension, s)\n",
    "    p(\"Vitamin B12 deficiency\", vb12, s)\n",
    "    p(\"Depression\", depression, s)\n",
    "    p(\"Anxiety\", anxiety, s)\n",
    "    p(\"History of traumatic brain injury\", trauma, s)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main program\n",
    "df = list()\n",
    "for ind in range(2,6):\n",
    "    df.append(pd.read_csv('AD-Early-Prediction/Dataset_1/' + str(ind)+'visit_combined.csv', header=0))\n",
    "\n",
    "print(\"CN group stats:\")\n",
    "analyze(CN_list)\n",
    "print(\"\\nCN_MCI group stats:\")\n",
    "analyze(CN_MCI_list)\n",
    "print(\"\\nMCI group stats:\")\n",
    "analyze(MCI_list)\n",
    "print(\"\\nMCI_AD group stats:\")\n",
    "analyze(MCI_AD_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PET scan hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv('fdgpet_npdka.csv', header=0)\n",
    "\n",
    "c1=0\n",
    "c2=0\n",
    "c3=0\n",
    "\n",
    "for ind in range(2,11):\n",
    "    csv = pd.read_csv('AD-Early-Prediction/Dataset_1/' + str(ind)+'visit_combined.csv', header=0)\n",
    "    ids = csv['ID']\n",
    "    for i in ids:\n",
    "        match=len(df[df['NACCID']==i])\n",
    "        if (match==0): continue\n",
    "        elif (match==1):c1+=1\n",
    "        elif (match==2): c2+=1\n",
    "        else: c3+=1\n",
    "\n",
    "print(c1)\n",
    "print(c2)\n",
    "print(c3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95% CI calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lz000\\AppData\\Local\\Temp\\ipykernel_9300\\3891691129.py:6: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('investigator_nacc67.csv', header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For 2 visits cohort:\n",
      "Mean: 16.62569178373776\n",
      "Std Err: 0.20201735637563076\n",
      "95% Confidence Interval: (np.float64(16.229438584430763), np.float64(17.021944983044758))\n",
      "\n",
      "For 3 visits cohort:\n",
      "Mean: 15.6892455567646\n",
      "Std Err: 0.17032337808334863\n",
      "95% Confidence Interval: (np.float64(15.355197774690769), np.float64(16.02329333883843))\n",
      "\n",
      "For 4 visits cohort:\n",
      "Mean: 14.905227181342985\n",
      "Std Err: 0.1216408840874867\n",
      "95% Confidence Interval: (np.float64(14.66669929781618), np.float64(15.14375506486979))\n",
      "\n",
      "For 5 visits cohort:\n",
      "Mean: 14.854480593607306\n",
      "Std Err: 0.14495864530627323\n",
      "95% Confidence Interval: (np.float64(14.5702195220155), np.float64(15.138741665199111))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# this is the huge dataset.\n",
    "df = pd.read_csv('investigator_nacc67.csv', header=0)\n",
    "\n",
    "# for all ids given in the list, add all their visit intervals to a new list and return it.\n",
    "def find_interval(list):\n",
    "    intervals = []\n",
    "    for i in list:\n",
    "        match=df[df['NACCID']==i]\n",
    "        # sort by visit dates\n",
    "        match=match.sort_values(by=match.columns[11])\n",
    "        for j in range(1,len(match)):\n",
    "            # add every interval (in months) to a list\n",
    "            intervals.append((int(match.iat[j,11])-int(match.iat[j-1,11]))/30.0)\n",
    "    return intervals\n",
    "\n",
    "def calc_CI(data):\n",
    "    # Calculate sample mean and standard error\n",
    "    mean = np.mean(data)\n",
    "    std_err = stats.sem(data)  # Standard error of the mean\n",
    "\n",
    "    # Compute 95% confidence interval\n",
    "    confidence = 0.95\n",
    "    ci = stats.t.interval(confidence, len(data)-1, loc=mean, scale=std_err)\n",
    "\n",
    "    print(f\"Mean: {mean}\")\n",
    "    print(f\"Std Err: {std_err}\")\n",
    "    print(f\"95% Confidence Interval: {ci}\")\n",
    "\n",
    "# main program: for cohorts 2-5\n",
    "for ind in range(2,6):\n",
    "    csv = pd.read_csv('AD-Early-Prediction/Dataset_1/' + str(ind)+'visit_combined.csv', header=0)\n",
    "    print(f\"\\nFor {ind} visits cohort:\")\n",
    "    calc_CI(find_interval(csv['ID']))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
